{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Workspace name",
			"defaultValue": "synapseeastuspombo"
		},
		"synapseeastuspombo-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'synapseeastuspombo-WorkspaceDefaultSqlServer'",
			"defaultValue": "Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=tcp:synapseeastuspombo.sql.azuresynapse.net,1433;Initial Catalog=@{linkedService().DBName}"
		},
		"synapseeastuspombo-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://eastussynapse.dfs.core.windows.net"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/pipelineendtoend')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "training",
						"type": "SynapseNotebook",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "runONNXmodel",
								"type": "NotebookReference"
							},
							"snapshot": true,
							"sparkPool": {
								"referenceName": "aa",
								"type": "BigDataPoolReference"
							},
							"executorSize": "Small",
							"conf": {
								"spark.dynamicAllocation.enabled": null,
								"spark.dynamicAllocation.minExecutors": null,
								"spark.dynamicAllocation.maxExecutors": null
							},
							"driverSize": "Small",
							"numExecutors": null
						}
					},
					{
						"name": "notebookToPrepareModel",
						"type": "SynapseNotebook",
						"dependsOn": [
							{
								"activity": "training",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "GetModelFromAMLPorcupine",
								"type": "NotebookReference"
							},
							"parameters": {
								"experiment_name": {
									"value": {
										"value": "@activity('training').output.status.Output.result.exitValue",
										"type": "Expression"
									},
									"type": "string"
								}
							},
							"snapshot": true,
							"executorSize": "Small",
							"conf": {
								"spark.dynamicAllocation.enabled": null,
								"spark.dynamicAllocation.minExecutors": null,
								"spark.dynamicAllocation.maxExecutors": null
							},
							"driverSize": "Small",
							"numExecutors": null
						}
					},
					{
						"name": "SQL pool stored procedure1",
						"type": "SqlPoolStoredProcedure",
						"dependsOn": [
							{
								"activity": "notebookToPrepareModel",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"sqlPool": {
							"referenceName": "aa",
							"type": "SqlPoolReference"
						},
						"typeProperties": {
							"storedProcedureName": "[dbo].[procedureToGetNewModel]",
							"storedProcedureParameters": {
								"artifactlocation": {
									"value": {
										"value": "@activity('notebookToPrepareModel').output.status.Output.result.exitValue",
										"type": "Expression"
									},
									"type": "String"
								}
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": [],
				"lastPublishTime": "2022-12-12T14:56:59Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/notebooks/runONNXmodel')]",
				"[concat(variables('workspaceId'), '/bigDataPools/aa')]",
				"[concat(variables('workspaceId'), '/notebooks/GetModelFromAMLPorcupine')]",
				"[concat(variables('workspaceId'), '/sqlPools/aa')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/synapseeastuspombo-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('synapseeastuspombo-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/synapseeastuspombo-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('synapseeastuspombo-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/procpipelineautomlinference')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "-- Create a stored procedure for storing the scoring script.\nCREATE PROCEDURE storedproctokeepinference\nAS\nBEGIN\n-- Select input scoring data and assign aliases.\nWITH InputData AS\n(\n    SELECT\n        CAST([fareAmount] AS [real]) AS [fareAmount],\n        CAST([paymentType] AS [bigint]) AS [paymentType],\n        CAST([passengerCount] AS [bigint]) AS [passengerCount],\n        CAST([tripDistance] AS [real]) AS [tripDistance],\n        [tripTimeSecs],\n        CAST([pickupTimeBin] AS [varchar]) AS [pickupTimeBin]\n    FROM [dbo].[nyc_taxi]\n)\n-- Using T-SQL Predict command to score machine learning models. \nSELECT *\nFROM PREDICT (MODEL = (SELECT [model] FROM tabletokeepmodel WHERE [ID] = 'pombosynapse1-tablenyc-20221124065701-Best:1'),\n              DATA = InputData,\n              RUNTIME = ONNX) WITH ([label] [bigint])\nEND\nGO\n\n-- Execute the above stored procedure.\nEXEC storedproctokeepinference",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/procpipelineautomlmodel')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "\n\n\n--\ndrop PROCEDURE procedureToGetNewModel;\nCREATE PROCEDURE procedureToGetNewModel @artifactlocation VARCHAR(max)\nAS\nCREATE TABLE #temp ( [model] [varbinary](max) ) WITH ( DISTRIBUTION = ROUND_ROBIN, HEAP );\nDECLARE @pathVar AS VARCHAR(max), @copyStmt as VARCHAR(max);\n\nset @pathVar = '''' +'https://pomboadlsgen22.dfs.core.windows.net/blobtest/output/' + @artifactlocation + '/outputcsharp1.tmp' + '''';\nset @copyStmt = 'COPY INTO #temp ( model ) FROM ' + @pathVar + ' WITH ( FILE_TYPE = ''CSV'' )';\n\nPRINT @copyStmt\nexec(@copyStmt);\n\ntruncate table tabletokeepmodel;\nINSERT INTO tabletokeepmodel ( [ID], [name], [description], [version], [created_time], [created_by], [framework], [model], [inputs_schema], [outputs_schema] ) SELECT 'pombosynapse1-tablenyc-20221124065701-Best:1', 'pombosynapse1-tablenyc-20221124065701-Best', NULL, 1, GETDATE(), 'c93b4133-9a61-49ec-b389-25fc5f0e047d', 'Custom', t.model, '[{\"name\": \"fareAmount\", \"type\": \"float\"}, {\"name\": \"paymentType\", \"type\": \"long\"}, {\"name\": \"passengerCount\", \"type\": \"long\"}, {\"name\": \"tripDistance\", \"type\": \"float\"}, {\"name\": \"tripTimeSecs\", \"type\": \"long\"}, {\"name\": \"pickupTimeBin\", \"type\": \"string\"}]', '[{\"name\": \"label\", \"type\": \"long\"}, {\"name\": \"probabilities\", \"type\": \"float\"}]' FROM #temp t;\nGO\n\n\nEXEC procedureToGetNewModel 'pombosynapse1-tablenyc-20221124065701_artifact'\n--\n\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/GetModelFromAMLPorcupine')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "aa",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "63160da7-a867-4ccc-aec0-97e5f586c8d2"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/fd75343a-2f47-43cd-bd82-c1ba01988d56/resourceGroups/pomboRG/providers/Microsoft.Synapse/workspaces/synapseeastuspombo/bigDataPools/aa",
						"name": "aa",
						"type": "Spark",
						"endpoint": "https://synapseeastuspombo.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/aa",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 8,
						"memory": 56
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"tags": [
								"parameters"
							]
						},
						"source": [
							"experiment_name = \"TO_INPUT\""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"source": [
							"import azureml.core\r\n",
							"from azureml.core import Experiment, Workspace, Dataset, Datastore\r\n",
							"from azureml.train.automl import AutoMLConfig\r\n",
							"from notebookutils import mssparkutils\r\n",
							"from azureml.data.dataset_factory import TabularDatasetFactory\r\n",
							"\r\n",
							"linkedService_name = \"AzureMLService2\"\r\n",
							"\r\n",
							"ws = mssparkutils.azureML.getWorkspace(linkedService_name)\r\n",
							"experiment = Experiment(ws, experiment_name)"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"experiment"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"for i in experiment.get_runs():\r\n",
							"    i.download_files()"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from os.path import join as osjoin\r\n",
							"from os import listdir\r\n",
							"artifactlocation = str(experiment_name)+\"_artifact\"\r\n",
							"datadir= osjoin(\".\",artifactlocation)\r\n",
							"local_files = [ osjoin(datadir,f) for f in listdir(datadir) if \".onnx\" in f ]\r\n",
							"local_files"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"spark.createDataFrame([artifactlocation], \"string\").toDF(\"age\").createOrReplaceTempView(\"mytemptable\")"
						],
						"outputs": [],
						"execution_count": 33
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"select * from mytemptable"
						],
						"outputs": [],
						"execution_count": 73
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "csharp"
							}
						},
						"source": [
							"%%csharp\r\n",
							"DataFrame dataFrame = spark.Read().Table(\"mytemptable\");\r\n",
							"string x = dataFrame.First().Values.GetValue(0).ToString();\r\n",
							"x"
						],
						"outputs": [],
						"execution_count": 81
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "csharp"
							}
						},
						"source": [
							"%%csharp\r\n",
							"using System;\r\n",
							"using System.IO;\r\n",
							"string pathonnx = @\"./\" + x + \"/model.onnx\";\r\n",
							"string pathtmp = @\"./\" + x + \"/outputcsharp1.tmp\"; \r\n",
							"\r\n",
							"//string path = @\"./pombosynapse1-tablenyc-20221124065701_artifact/model.onnx\";\r\n",
							"//string path1 = @\"./pombosynapse1-tablenyc-20221124065701_artifact/outputcsharp1.tmp\";\r\n",
							"\r\n",
							"System.IO.StreamWriter objWriter;\r\n",
							"// Calling the ReadAllBytes() function\r\n",
							"byte[] readText = File.ReadAllBytes(pathonnx);\r\n",
							"string s1;\r\n",
							"\r\n",
							"s1 = BitConverter.ToString(readText).Replace(\"-\",\"\");\r\n",
							"objWriter = new System.IO.StreamWriter(pathtmp);\r\n",
							"objWriter.WriteLine(s1);\r\n",
							"objWriter.Close();"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import azureml.core.datastore\r\n",
							"from azureml.core import Dataset\r\n",
							"datastore = azureml.core.datastore.Datastore.get(ws,\"datastoreadlsgen22\")"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# upload-data.py\r\n",
							"from azureml.core import Workspace\r\n",
							"from azureml.core import Dataset\r\n",
							"from azureml.data.datapath import DataPath\r\n",
							"\r\n",
							"Dataset.File.upload_directory(src_dir=artifactlocation, \r\n",
							"                              target=DataPath(datastore, \"output/\"+artifactlocation)\r\n",
							"                             )"
						],
						"outputs": [],
						"execution_count": 17
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"mssparkutils.notebook.exit(artifactlocation)"
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/runONNXmodel')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "aa",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "c931af13-2919-4d8a-802e-75cbfaf84a60"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/fd75343a-2f47-43cd-bd82-c1ba01988d56/resourceGroups/pomboRG/providers/Microsoft.Synapse/workspaces/synapseeastuspombo/bigDataPools/aa",
						"name": "aa",
						"type": "Spark",
						"endpoint": "https://synapseeastuspombo.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/aa",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 8,
						"memory": 56
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"import azureml.core\n",
							"\n",
							"from azureml.core import Experiment, Workspace, Dataset, Datastore\n",
							"from azureml.train.automl import AutoMLConfig\n",
							"from notebookutils import mssparkutils\n",
							"from azureml.data.dataset_factory import TabularDatasetFactory"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from datetime import datetime\r\n",
							"datepipe = datetime.today().strftime('%Y-%m-%d')\r\n",
							"datepipe = datepipe.replace('-','')"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"source": [
							"linkedService_name = \"AzureMLService2\"\n",
							"experiment_name = \"pombosynapse1-tablenyc\" + str(datepipe)\n",
							"\n",
							"ws = mssparkutils.azureML.getWorkspace(linkedService_name)\n",
							"experiment = Experiment(ws, experiment_name)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"source": [
							"df = spark.sql(\"SELECT * FROM default.tablenyc\")\n",
							"\n",
							"datastore = Datastore.get_default(ws)\n",
							"dataset = TabularDatasetFactory.register_spark_dataframe(df, datastore, name = experiment_name + \"-dataset\")"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"source": [
							"automl_config = AutoMLConfig(spark_context = sc,\n",
							"                             task = \"classification\",\n",
							"                             training_data = dataset,\n",
							"                             label_column_name = \"tipped\",\n",
							"                             primary_metric = \"accuracy\",\n",
							"                             experiment_timeout_hours = 0.25,\n",
							"                             max_concurrent_iterations = 2,\n",
							"                             enable_onnx_compatible_models = True)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"source": [
							"run = experiment.submit(automl_config)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"source": [
							"displayHTML(\"<a href={} target='_blank'>Your experiment in Azure Machine Learning portal: {}</a>\".format(run.get_portal_url(), run.id))"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"source": [
							"run.wait_for_completion()\n",
							"\n",
							"import onnxruntime\n",
							"import mlflow\n",
							"import mlflow.onnx\n",
							"\n",
							"from mlflow.models.signature import ModelSignature\n",
							"from mlflow.types import DataType\n",
							"from mlflow.types.schema import ColSpec, Schema\n",
							"\n",
							"# Get best model from automl run\n",
							"best_run, onnx_model = run.get_output(return_onnx_model=True)\n",
							"\n",
							"# Define utility functions to infer the schema of ONNX model\n",
							"def _infer_schema(data):\n",
							"    res = []\n",
							"    for _, col in enumerate(data):\n",
							"        t = col.type.replace(\"tensor(\", \"\").replace(\")\", \"\")\n",
							"        if t in [\"bool\"]:\n",
							"            dt = DataType.boolean\n",
							"        elif t in [\"int8\", \"uint8\", \"int16\", \"uint16\", \"int32\"]:\n",
							"            dt = DateType.integer\n",
							"        elif t in [\"uint32\", \"int64\"]:\n",
							"            dt = DataType.long\n",
							"        elif t in [\"float16\", \"bfloat16\", \"float\"]:\n",
							"            dt = DataType.float\n",
							"        elif t in [\"double\"]:\n",
							"            dt = DataType.double\n",
							"        elif t in [\"string\"]:\n",
							"            dt = DataType.string\n",
							"        else:\n",
							"            raise Exception(\"Unsupported type: \" + t)\n",
							"        res.append(ColSpec(type=dt, name=col.name))\n",
							"    return Schema(res)\n",
							"\n",
							"def _infer_signature(onnx_model):\n",
							"    onnx_model_bytes = onnx_model.SerializeToString()\n",
							"    onnx_runtime = onnxruntime.InferenceSession(onnx_model_bytes)\n",
							"    inputs = _infer_schema(onnx_runtime.get_inputs())\n",
							"    outputs = _infer_schema(onnx_runtime.get_outputs())\n",
							"    return ModelSignature(inputs, outputs)\n",
							"\n",
							"# Infer signature of ONNX model\n",
							"signature = _infer_signature(onnx_model)\n",
							"\n",
							"artifact_path = experiment_name + \"_artifact\"\n",
							"mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
							"mlflow.set_experiment(experiment_name)\n",
							"\n",
							"with mlflow.start_run() as run:\n",
							"    # Save the model to the outputs directory for capture\n",
							"    mlflow.onnx.log_model(onnx_model, artifact_path, signature=signature)\n",
							"\n",
							"    # Register the model to AML model registry\n",
							"    mlflow.register_model(\"runs:/\" + run.info.run_id + \"/\" + artifact_path, \"pombosynapse1-tablenyc-Best\")"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"mssparkutils.notebook.exit(experiment_name)"
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/aa')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 15
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 10,
					"minNodeCount": 3
				},
				"nodeCount": 10,
				"nodeSize": "Medium",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.2",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "eastus"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/aa')]",
			"type": "Microsoft.Synapse/workspaces/sqlPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"collation": "SQL_Latin1_General_CP1_CI_AS",
				"maxSizeBytes": 263882790666240,
				"annotations": []
			},
			"dependsOn": [],
			"location": "eastus"
		}
	]
}